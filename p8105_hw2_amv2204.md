Homework 2
================
Ashwini Varghese
2022-10-05

## Preparation:

We’ll start by having a code chunk in the beginning that loads all the
packages we will need for this homework.

``` r
library (tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1:

We will start by reading in the datafile using the `readr` function from
the `tidyverse` package and cleaning the data by using the `clean_names`
function from the `janitor` package. We will also retain certain
variables and convert the entry variable from a character variable to a
logical variable.

``` r
subway = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names() %>% 
    select(line, station_name, station_latitude, station_longitude, 
      starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% 
    mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>% 
    mutate(route8 = as.character(route8)) %>%  
    mutate(route9 = as.character(route9)) %>% 
    mutate(route10 = as.character(route10)) %>% 
    mutate(route11 = as.character(route11)) 
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

This dataset contains 20 columns and 1868 rows It has the 20 variables
that we selected it to keep. We imported the file, used the
`clean_names` function to do a quick clean. Then we selected what
variables we wanted to keep. Some of the route variables were in dbl
format instead of chr like most of the route variables so we changed
that. And lastly we truned the entry variable from character into a
logical variable.

This data is not tidy because the route variables should be converted
from a wide to long format.

We can use the following code to find the number of distinct stations:

``` r
subway %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

There are 465 distinct stations.

We can use the following code to find the number of ADA compliant
stations:

``` r
subway %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

There are 84 ADA compliant stations.

We can use the following code to find the proportion of station
entrances/exits without vending allow entrance:

``` r
subway %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

The proportion is 0.377.

``` r
subway %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
subway %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

There are 60 stations that serve the A train and of those, 17 are ADA
compliant.

## Problem 2:

Let’s start by reading and cleaning the Mr. Trash Wheel and Professor
Trash Wheel datasets.

``` r
trash = read_excel("./data/Trash_Wheel_Collection_Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls))) %>% 
  mutate(ID = "A")
```

``` r
professor = read_excel("./data/Trash_Wheel_Collection_Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(ID = "B")
```

Next we will combine both datasets into one dataset.

``` r
combo = merge(x = trash, y = professor, all = TRUE) %>% 
  select(ID, everything())
```

The new and combined dataset has 641 observations `nrow(combo)` and 15
variables `ncol(combo)`. All the variables exist both sets except for
the *sports_balls* variable; it came from the **trash** dataset. We can
distinguish which observation is from which dataset by the *ID*
variable; an *ID* value equal to A is for the **trash** dataset and an
*ID* value of B is for the **professor** dataset.

To find the total weight of trash collected by Professor Trash Wheel, we
can use the following code: `sum(subset(combo, ID == "B")$weight_tons)`,
which gives us the sum of the *weight_tons* variable restricted to the
observations from the **Professor** dataset, identified by *ID = B*. The
answer is 190.12 tons.

To find the total number of sports balls collected by Mr. Trash Wheel in
2020, we can use the following code:
`sum(subset(combo, ID == "A" & year == "2020")$sports_balls)`, which
gives us the sum of the *sports_balls* variable restricted to the
observations from the **Trash** dataset, identified by *ID = A*, and
only in the year 2020. The answer is 856 sports balls.

## Problem 3:

Clean up the pols-month file:

``` r
pols = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
    janitor::clean_names() %>% 
    separate(mon, sep = "-", into = c("year", "month", "day")) %>%
    mutate(month = month.name[as.numeric(month)]) %>% 
    mutate(year = as.numeric(year)) %>% 
    mutate(month = factor(month, levels = month.name)) %>% 
    mutate(president = case_when(prez_gop == 1 ~ "gop", TRUE ~ "dem")) %>% 
    select(-day, -prez_gop, -prez_dem) %>% 
    arrange(year, month)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Clean up the snp file:

``` r
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
    janitor::clean_names() %>% 
    separate(date, sep = "/", into = c("month", "day", "year")) %>% 
    mutate(month = month.name[as.numeric(month)]) %>% 
    mutate(century = case_when(year < 16 ~ 2000, TRUE ~ 1900)) %>% 
    mutate(year = as.numeric(year)) %>% 
    mutate(year = year + century) %>% 
    select(year, month, close) %>% 
    mutate(month = factor(month, levels = month.name)) %>% 
    arrange(year, month) 
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Now tidy the unemployment file:

``` r
unemploy = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
    janitor::clean_names() %>% 
    pivot_longer(
      jan:dec,
      names_to = "month",
      values_to = "percent_unemploy") %>% 
    mutate(month = as.factor(month)) %>% 
    mutate(month = month.name[as.numeric(month)]) %>% 
    mutate(month = as.factor(month)) %>% 
    mutate(month = factor(month, levels = month.name)) %>% 
    arrange(year, month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Now we will create a fully merged dataset.

First we will merge `snp` into `pols`:

``` r
first = left_join(pols, snp, by = c("year", "month"))
```

Then we will merge the `unemploy` file into this new merged `first`
file:

``` r
total = left_join(first, unemploy, by = c("year", "month"))
```

The **snp** dataset has just 3 variables: the *close* variable,
untouched, and then the *month* and *year* that we created by separating
the date. The **pols** dataset has the same *month* and *year* that we
made like in the **snp** dataset. It also has many of the original
variables, as well as a new variable called *president* which was
created logically based off the *prez_dem* and *prez_gop* variables. The
**unemploy** dataset has also 3 variables, with the *month* and *year*
variables made by separating the date and the *percent_unemploy*
variable made by the `pivot_longer` function.

The final dataset **total** has 822 observations (`nrow(total`) and 11
variables (`ncol(total`). We can find the range of years with the
following code: `range(total$year)`, which is from 1947 to 2015. The key
variables are *year* and *month* which was present in all 3 datafiles
and was used to perform all the merges.
