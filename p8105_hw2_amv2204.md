Homework 2
================
Ashwini Varghese
2022-10-05

## Preparation:

We’ll start by having a code chunk in the beginning that loads all the
packages we will need for this homework.

``` r
library(tidyverse)
library(readxl)
```

## Problem 1:

We will start by reading in the datafile using the `readr` function from
the `tidyverse` package and cleaning the data by using the `clean_names`
function from the `janitor` package. We will also retain certain
variables and convert the entry variable from a character variable to a
logical variable.

``` r
subway = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names() %>% 
    select(line, station_name, station_latitude, station_longitude, 
      starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% 
    mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>% 
    mutate(route8 = as.character(route8)) %>%  
    mutate(route9 = as.character(route9)) %>% 
    mutate(route10 = as.character(route10)) %>% 
    mutate(route11 = as.character(route11)) 
```

This dataset contains 20 columns and 1868 rows It has the 20 variables
that we selected it to keep. We imported the file, used the
`clean_names` function to do a quick clean. Then we selected what
variables we wanted to keep. Some of the route variables were in dbl
format instead of chr like most of the route variables so we changed
that. And lastly we truned the entry variable from character into a
logical variable.

This data is not tidy because the route variables should be converted
from a wide to long format.

We can use the following code to find the number of distinct stations:

``` r
subway %>% 
  select(station_name, line) %>% 
  distinct
```

There are 465 distinct stations.

We can use the following code to find the number of ADA compliant
stations:

``` r
subway %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

There are 84 ADA compliant stations.

We can use the following code to find the proportion of station
entrances/exits without vending allow entrance:

``` r
subway %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

The proportion is 0.377.

``` r
subway %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

subway %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

There are 60 stations that serve the A train and of those, 17 are ADA
compliant.

## Problem 2:

Let’s start by reading and cleaning the Mr. Trash Wheel and Professor
Trash Wheel datasets.

``` r
trash = read_excel("./data/Trash_Wheel_Collection_Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls))) %>% 
  mutate(ID = "A")
```

``` r
professor = read_excel("./data/Trash_Wheel_Collection_Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(ID = "B")
```

Next we will combine both datasets into one dataset.

``` r
combo = merge(x = trash, y = professor, all = TRUE) %>% 
  select(ID, everything())
```

The new and combined dataset is a full merge and has 641 observations
(`nrow(combo)`) and 15 variables (`ncol(combo)`). All the variables
exist in both sets except for the *sports_balls* variable; it came from
the **trash** dataset. We can distinguish which observation is from
which dataset by the *ID* variable; an *ID* value equal to A is for the
**trash** dataset and an *ID* value of B is for the **professor**
dataset.

To find the total weight of trash collected by Professor Trash Wheel, we
can use the following code: `sum(subset(combo, ID == "B")$weight_tons)`,
which gives us the sum of the *weight_tons* variable restricted to the
observations from the **Professor** dataset, identified by *ID = B*. The
answer is 190.12 tons.

To find the total number of sports balls collected by Mr. Trash Wheel in
2020, we can use the following code:
`sum(subset(combo, ID == "A" & year == "2020")$sports_balls)`, which
gives us the sum of the *sports_balls* variable restricted to the
observations from the **Trash** dataset, identified by *ID = A*, and
only in the year 2020. The answer is 856 sports balls.

## Problem 3:

Clean up the pols-month file:

``` r
pols = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
    janitor::clean_names() %>% 
    separate(mon, sep = "-", into = c("year", "month", "day")) %>%
    mutate(month = month.name[as.numeric(month)]) %>% 
    mutate(year = as.numeric(year)) %>% 
    mutate(month = factor(month, levels = month.name)) %>% 
    mutate(president = case_when(prez_gop == 1 ~ "gop", TRUE ~ "dem")) %>% 
    select(-day, -prez_gop, -prez_dem) %>% 
    arrange(year, month)
```

Clean up the snp file:

``` r
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
    janitor::clean_names() %>% 
    separate(date, sep = "/", into = c("month", "day", "year")) %>% 
    mutate(month = month.name[as.numeric(month)]) %>% 
    mutate(century = case_when(year < 16 ~ 2000, TRUE ~ 1900)) %>% 
    mutate(year = as.numeric(year)) %>% 
    mutate(year = year + century) %>% 
    select(year, month, close) %>% 
    mutate(month = factor(month, levels = month.name)) %>% 
    arrange(year, month) 
```

Now tidy the unemployment file:

``` r
unemploy = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
    janitor::clean_names() %>% 
    pivot_longer(
      jan:dec,
      names_to = "month",
      values_to = "percent_unemploy") %>% 
    mutate(month = as.factor(month)) %>% 
    mutate(month = month.name[as.numeric(month)]) %>% 
    mutate(month = as.factor(month)) %>% 
    mutate(month = factor(month, levels = month.name)) %>% 
    arrange(year, month)
```

Now we will create a merged dataset in 2 steps.

First we will merge `snp` into `pols`:

``` r
first = left_join(pols, snp, by = c("year", "month"))
```

Then we will merge the `unemploy` file into this new merged `first`
file:

``` r
total = left_join(first, unemploy, by = c("year", "month"))
```

The **snp** dataset has just 3 variables: the *close* variable, which
was untouched, and then *month* and *year* that we created by separating
the date. The **pols** dataset has the same *month* and *year* that we
made like in the **snp** dataset. It also has many of the original
variables, as well as a new variable called *president* which was
created logically based off the *prez_dem* and *prez_gop* variables. The
**unemploy** dataset has also 3 variables, with the *month* and *year*
variables made by separating the date and the *percent_unemploy*
variable made by the `pivot_longer` function.

The final dataset **total** has 822 observations (`nrow(total`) and 11
variables (`ncol(total`). We can find the range of years with the
following code: `range(total$year)`, which is from 1947 to 2015. The key
variables are *year* and *month* which was present in all 3 datafiles
and was used to perform all the merges.
